defaults:
  - base_model

arch:
  type: enc
  encoder: cnn
lib: factored_rl
flatten_input: false
cnn:
  activation: relu
  final_activation: relu
mlp:
  activation: relu
  final_activation: tanh
qnet:
  n_hidden_layers: 1
  n_units_per_layer: 64
  activation: relu
  final_activation: ""
